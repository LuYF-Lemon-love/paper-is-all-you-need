\section{Conclusion}

In this report, we introduce the ChatGLM family of large language models from GLM-130B to GLM-4 (All Tools). 
Over the past one and half years, we have made great progress in understanding various perspectives of large language models from our first-hand experiences. 
With the development of each model generation, the team has learned and applied more effective and more efficient  strategies for both model pre-training and alignment. 
The recent ChatGLM models---GLM-4 (0116, 0520), GLM-4-Air (0605), and GLM-4 All Tools---demonstrate significant advancements in understanding and executing complex tasks by autonomously employing external tools and functions. 
These GLM-4 models have achieved performance on par with, and in some cases superior to, state-of-the-art models such as GPT-4 Turbo, Claude 3 Opus, and Gemini 1.5 Pro, particularly in handling tasks relevant to the Chinese language. 
In addition, we are committed to promoting accessibility and safety of LLMs through open releasing our model weights and techniques developed throughout this journey. 
Our open models, including language, code, and vision models, have attracted over 10 million downloads on Hugging Face in the year 2023 alone. 
Currently, we are working on more capable models with everything we have learned to date. 
In the future, we will continue democratizing cutting-edge LLM technologies through open sourcing, and push the boundary of model capabilities towards the mission of teaching machines to think like humans.
